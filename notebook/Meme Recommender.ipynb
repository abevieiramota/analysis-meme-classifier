{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/dataset.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove entradas com tamanho total < 30 caracteres\n",
    "df = df[df.apply(lambda r: len(r['text0'] + r['text1']) >= 30, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kermit-The-Frog-Drinking-Tea             118\n",
       "What-If-I-Told-You                       115\n",
       "Philosoraptor                            114\n",
       "Scumbag-Steve                            113\n",
       "The-Most-Interesting-Man-In-The-World    112\n",
       "Joseph-Ducreux                           112\n",
       "Bad-Luck-Brian                           111\n",
       "One-Does-Not-Simply                      110\n",
       "Good-Guy-Greg                            110\n",
       "First-World-Problems                     107\n",
       "Willy-Wonka                              106\n",
       "Yo-Dawg                                  104\n",
       "Winter-Is-Coming                         102\n",
       "Conspiracy-Keanu                         101\n",
       "Futurama-Fry                              95\n",
       "Grumpy-Cat                                91\n",
       "Insanity-Wolf                             88\n",
       "Success-Kid                               86\n",
       "X-X-Everywhere                            75\n",
       "Y-U-No                                    63\n",
       "Forever-Alone                             43\n",
       "All-The-Things                            37\n",
       "Ancient-Aliens                            33\n",
       "X-All-The-Things                           6\n",
       "Name: meme, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.meme.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df.meme.isin(['Grumpy-Cat', 'Willy-Wonka', 'All-The-Things', 'Ancient-Aliens', 'Y-U-No', 'Kermit-The-Frog-Drinking-Tea'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    ('n_neighbors', [2, 3, 5]),\n",
    "    ('metric', ['minkowski']),\n",
    "    ('text0_ngram_range', [(2,3), (1, 2)]),\n",
    "    ('text1_ngram_range', [(2,3), (1, 2)]),\n",
    "    ('text_ngram_range', [(2,4), (1, 3)])\n",
    "]\n",
    "\n",
    "meme_enc = LabelEncoder().fit(df.meme.unique())\n",
    "\n",
    "y = meme_enc.transform(df.meme)\n",
    "\n",
    "for n_neighbor, metric, text0_ngram_range, text1_ngram_range, text_ngram_range in itertools.product(*map(lambda x: x[1], params)):\n",
    "\n",
    "    bag_of_tagram_text0 = df.text0.apply(lambda text: ' '.join(map(lambda par: par[1], nltk.pos_tag(word_tokenize(text)))))\n",
    "    bag_of_tagram_text1 = df.text1.apply(lambda text: ' '.join(map(lambda par: par[1], nltk.pos_tag(word_tokenize(text)))))\n",
    "    \n",
    "    tfidf_text0 = TfidfVectorizer(ngram_range=text0_ngram_range, min_df=.01).fit(bag_of_tagram_text0)\n",
    "    tfidf_text1 = TfidfVectorizer(ngram_range=text1_ngram_range, min_df=.01).fit(bag_of_tagram_text1)\n",
    "    tfidf_text = TfidfVectorizer(ngram_range=text_ngram_range, min_df=0).fit(df.apply(lambda r: r['text0'] + ' ' + r['text1'], axis=1))\n",
    "    \n",
    "    X0 = tfidf_text0.transform(bag_of_tagram_text0)\n",
    "    X1 = tfidf_text1.transform(bag_of_tagram_text1)\n",
    "    X2 = tfidf_text.transform(df.apply(lambda r: r['text0'] + ' ' + r['text1'], axis=1))\n",
    "    \n",
    "    X = hstack((X0, X1, X2))\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbor, metric=metric)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 10, test_size=.3)\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    print({'n_neighbor': n_neighbor,\n",
    "           'metric': metric,\n",
    "           'text0_ngram_range': text0_ngram_range,\n",
    "           'text1_ngram_range': text1_ngram_range,\n",
    "           'text_ngram_range': text_ngram_range})\n",
    "    print(\"\\n\")\n",
    "    print(accuracy_score(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_enc = LabelEncoder().fit(df.meme.unique())\n",
    "\n",
    "y = meme_enc.transform(df.meme)\n",
    "\n",
    "bag_of_tagram_text0 = df.text0.apply(lambda text: ' '.join(map(lambda par: par[1], nltk.pos_tag(word_tokenize(text)))))\n",
    "bag_of_tagram_text1 = df.text1.apply(lambda text: ' '.join(map(lambda par: par[1], nltk.pos_tag(word_tokenize(text)))))\n",
    "\n",
    "tfidf_text0 = TfidfVectorizer(ngram_range=(1, 3), min_df=.02).fit(bag_of_tagram_text0)\n",
    "tfidf_text1 = TfidfVectorizer(ngram_range=(2, 3), min_df=.02).fit(bag_of_tagram_text1)\n",
    "tfidf_text = TfidfVectorizer(ngram_range=(3, 6), analyzer='char').fit(df.apply(lambda r: r['text0'] + ' ' + r['text1'], axis=1))\n",
    "\n",
    "X0 = tfidf_text0.transform(bag_of_tagram_text0)\n",
    "X1 = tfidf_text1.transform(bag_of_tagram_text1)\n",
    "X2 = tfidf_text.transform(df.apply(lambda r: r['text0'] + ' ' + r['text1'], axis=1))\n",
    "\n",
    "X_all = hstack((X0, X1, X2))\n",
    "\n",
    "knn_all = KNeighborsClassifier(n_neighbors=5, metric='minkowski')\n",
    "\n",
    "knn_all.fit(X_all, y)\n",
    "\n",
    "knn_words = KNeighborsClassifier(n_neighbors=5, metric='minkowski')\n",
    "knn_words.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92        37\n",
      "          1       0.71      0.97      0.82        33\n",
      "          2       0.86      0.63      0.73        91\n",
      "          3       0.85      0.97      0.91       118\n",
      "          4       0.83      0.85      0.84       106\n",
      "          5       0.75      0.62      0.68        63\n",
      "\n",
      "avg / total       0.83      0.82      0.82       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, knn_all.predict(X_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.97      0.87        37\n",
      "          1       0.85      0.88      0.87        33\n",
      "          2       0.86      0.68      0.76        91\n",
      "          3       0.88      0.97      0.92       118\n",
      "          4       0.89      0.88      0.88       106\n",
      "          5       0.80      0.76      0.78        63\n",
      "\n",
      "avg / total       0.86      0.85      0.85       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, knn_words.predict(X2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def qual_meme_all(text0, text1):\n",
    "    return meme_enc.inverse_transform(\\\n",
    "                    knn_all.predict(\\\n",
    "                    hstack((\\\n",
    "                            tfidf_text0.transform([text0]), \n",
    "                            tfidf_text1.transform([text1]), \n",
    "                            tfidf_text.transform([text0 + ' ' + text1])\\\n",
    "                          )\\\n",
    "                         )\\\n",
    "                               )\\\n",
    "                                      )[0]\n",
    "\n",
    "def qual_meme_word(text0, text1):\n",
    "    return meme_enc.inverse_transform(\\\n",
    "                    knn_words.predict(\\\n",
    "                            tfidf_text.transform([text0 + ' ' + text1])\\\n",
    "                                      ))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have a nice day\n",
      "don't tell me what to do\n",
      "\n",
      "Grumpy-Cat->Grumpy-Cat\n",
      "\n",
      "-------\n",
      "\n",
      "I pretend I don't care but deep down\n",
      "I really still don't care\n",
      "\n",
      "Grumpy-Cat->Kermit-The-Frog-Drinking-Tea\n",
      "\n",
      "-------\n",
      "\n",
      "Lose\n",
      "All the blood\n",
      "\n",
      "X-All-The-Things->All-The-Things\n",
      "\n",
      "-------\n",
      "\n",
      "Friday night\n",
      "Damage all the organs\n",
      "\n",
      "X-All-The-Things->All-The-Things\n",
      "\n",
      "-------\n",
      "\n",
      "Fall asleep on couch... woke up in bed.\n",
      "aliens\n",
      "\n",
      "Ancient-Aliens->Ancient-Aliens\n",
      "\n",
      "-------\n",
      "\n",
      "We are not saying it was done by aliens\n",
      "But it was done by aliens\n",
      "\n",
      "Ancient-Aliens->Ancient-Aliens\n",
      "\n",
      "-------\n",
      "\n",
      "9gag\n",
      "y u no use me anymore\n",
      "\n",
      "Y-U-No->Y-U-No\n",
      "\n",
      "-------\n",
      "\n",
      "people\n",
      "y u no read this in normal voice\n",
      "\n",
      "Y-U-No->Y-U-No\n",
      "\n",
      "-------\n",
      "\n",
      "So you're blatantly pregnant and buying cigarettes\n",
      "but that's none of my business\n",
      "\n",
      "Kermit-The-Frog-Drinking-Tea->Kermit-The-Frog-Drinking-Tea\n",
      "\n",
      "-------\n",
      "\n",
      "Your phone's screen is brighter than your future\n",
      "but that's none of my business\n",
      "\n",
      "Kermit-The-Frog-Drinking-Tea->Kermit-The-Frog-Drinking-Tea\n",
      "\n",
      "-------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textos = [\n",
    "    ('Grumpy-Cat', 'have a nice day', 'don\\'t tell me what to do'),\n",
    "    ('Grumpy-Cat', 'I pretend I don\\'t care but deep down', 'I really still don\\'t care'),\n",
    "    ('X-All-The-Things', 'Lose', 'All the blood'),\n",
    "    ('X-All-The-Things', 'Friday night', 'Damage all the organs'),\n",
    "    ('Ancient-Aliens', 'Fall asleep on couch... woke up in bed.', 'aliens'),\n",
    "    ('Ancient-Aliens', 'We are not saying it was done by aliens', 'But it was done by aliens'),\n",
    "    ('Y-U-No', '9gag', 'y u no use me anymore'),\n",
    "    ('Y-U-No', 'people', 'y u no read this in normal voice'),\n",
    "    ('Kermit-The-Frog-Drinking-Tea', 'So you\\'re blatantly pregnant and buying cigarettes', 'but that\\'s none of my business'),\n",
    "    ('Kermit-The-Frog-Drinking-Tea', 'Your phone\\'s screen is brighter than your future', 'but that\\'s none of my business')\n",
    "]\n",
    "\n",
    "for meme, text0, text1 in textos:\n",
    "    \n",
    "    print(text0)\n",
    "    print(text1)\n",
    "    print()\n",
    "    print(meme + '->' + qual_meme_word(text0, text1))\n",
    "    print(\"\\n-------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
